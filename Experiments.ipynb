{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Experiments.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Carlo-pien/Projet_ML_2_MA1/blob/master/Experiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiments with unet model\n",
        "## Initializations"
      ],
      "metadata": {
        "id": "8XjgNdgNJ6pS"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PfGmLNCoqEb"
      },
      "source": [
        "!pip install einops\n",
        "!pip install pytorch-lightning\n",
        "!pip install -q -U segmentation-models-pytorch albumentations > /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ],
      "metadata": {
        "id": "F8OPSj1hJzba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os,sys\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import math\n",
        "from sklearn.model_selection import KFold\n",
        "import torch\n",
        "import torch.autograd as autograd\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torchvision.io import read_image\n",
        "from torchvision import transforms as transforms\n",
        "import albumentations.augmentations.transforms as tf\n",
        "from torchvision.transforms import Compose\n",
        "import albumentations as A\n",
        "import torchvision.transforms.functional as TF\n",
        "from einops import rearrange, reduce\n",
        "import pytorch_lightning as pl\n",
        "import cv2\n",
        "import os, cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random, tqdm\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import warnings\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import pytorch_lightning as pl\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "torch.manual_seed(1)"
      ],
      "metadata": {
        "id": "y5qKYKBnJ4EO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## System path definition"
      ],
      "metadata": {
        "id": "SjFOE1fwJ53p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('drive/MyDrive/Projet_ML/') \n",
        "#from Unet_model import Unet\n",
        "from Unet_model_lightning import Lit_Net"
      ],
      "metadata": {
        "id": "hb3botw3KRX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper functions"
      ],
      "metadata": {
        "id": "_Dk8x_s9LE9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper functions\n",
        "\n",
        "def load_image(infilename):\n",
        "    data = mpimg.imread(infilename)\n",
        "    return data\n",
        "\n",
        "def img_float_to_uint8(img):\n",
        "    rimg = img - np.min(img)\n",
        "    rimg = (rimg / np.max(rimg) * 255).round().astype(np.uint8)\n",
        "    return rimg\n",
        "\n",
        "# Concatenate an image and its groundtruth\n",
        "def concatenate_images(img, gt_img):\n",
        "    nChannels = len(gt_img.shape)\n",
        "    w = gt_img.shape[0]\n",
        "    h = gt_img.shape[1]\n",
        "    if nChannels == 3:\n",
        "        cimg = np.concatenate((img, gt_img), axis=1)\n",
        "    else:\n",
        "        gt_img_3c = np.zeros((w, h, 3), dtype=np.uint8)\n",
        "        gt_img8 = img_float_to_uint8(gt_img)          \n",
        "        gt_img_3c[:,:,0] = gt_img8\n",
        "        gt_img_3c[:,:,1] = gt_img8\n",
        "        gt_img_3c[:,:,2] = gt_img8\n",
        "        img8 = img_float_to_uint8(img)\n",
        "        cimg = np.concatenate((img8, gt_img_3c), axis=1)\n",
        "    return cimg\n",
        "\n",
        "def to_RGB(mask):\n",
        "  return np.repeat(np.round(mask)[:, :, np.newaxis], 3, axis=2)\n",
        "\n",
        "def img_crop(im, w, h):\n",
        "    list_patches = []\n",
        "    imgwidth = im.shape[0]\n",
        "    imgheight = im.shape[1]\n",
        "    is_2d = len(im.shape) < 3\n",
        "    for i in range(0,imgheight,h):\n",
        "        for j in range(0,imgwidth,w):\n",
        "            if is_2d:\n",
        "                im_patch = im[j:j+w, i:i+h]\n",
        "            else:\n",
        "                im_patch = im[j:j+w, i:i+h, :]\n",
        "            list_patches.append(im_patch)\n",
        "    return list_patches"
      ],
      "metadata": {
        "id": "6F_priCBLDDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-7LkpvcC8aI"
      },
      "source": [
        "# Data loading and preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oW9rFk4o_Lk"
      },
      "source": [
        "root_dir = \"/content/drive/MyDrive/Projet_ML/training/\"\n",
        "n = 100\n",
        "image_dir = root_dir + \"images/\"\n",
        "files = os.listdir(image_dir)\n",
        "n = min(n, len(files))\n",
        "print(\"Loading \" + str(n) + \" images\")\n",
        "imgs = [load_image(image_dir + files[i]) for i in range(n)]\n",
        "print(files[0])\n",
        "\n",
        "gt_dir = root_dir + \"groundtruth/\"\n",
        "print(\"Loading \" + str(n) + \" images\")\n",
        "gt_imgs = [load_image(gt_dir + files[i]) for i in range(n)]\n",
        "print(files[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkPsEDB5pjfy"
      },
      "source": [
        "# Defining dataset and dataloaders\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5h8fxEMRppit"
      },
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self,images_np =  imgs, masks_np = gt_imgs, transform=None):\n",
        "        self.transform = transform\n",
        "        self.num_samples = np.array(images_np).shape[0]\n",
        "        self.images_np = images_np\n",
        "        self.masks_np = masks_np\n",
        "        \n",
        "    def __getitem__(self, index):        \n",
        "        if self.transform:\n",
        "            \n",
        "            img1 = np.array(self.images_np)[index,:,:,:]\n",
        "            msk1 = np.array(self.masks_np)[index,:,:]\n",
        "\n",
        "            #Add a dimension to masks and reshape it to have correct input for transformation\n",
        "            mask1 = np.expand_dims(msk1, axis = 0)\n",
        "            \n",
        "            mask1 = (rearrange(mask1, 'c h w -> h w c'))\n",
        "\n",
        "            #Applying the transformations\n",
        "            transformed = self.transform(image=img1, mask=mask1)\n",
        "            image11 = rearrange(transformed['image'], 'h w c -> c h w')\n",
        "            mask11 = rearrange(transformed['mask'], 'h w c -> c h w')\n",
        "            mask11 = np.squeeze(mask11, axis = 0)\n",
        "          \n",
        "        return image11, mask11\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.num_samples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defining our transformations\n",
        "\n",
        "Our dataset in a small dataset, hence it quickly became obivous that we had to resort to data augmentation techniques to create a more robust model. Initially, we tought about using a RandomSearch, GridSearch or even cross-validation to validate different transformations.\n",
        "\n",
        "Unfortunately, all of these methods required to high computation power for our means. On top of that, we'd have to optimize the other parameters such as learning rate or u-net level at the same time. This prooved infeasible to do within the given time and computational power.\n",
        "\n",
        "To test the transformations, we defined three groups:\n",
        "1.  A baseline group, in which we only use horizontal and vertical flips. These transformations do not alter the road geometry and are as such usefull.\n",
        "2.  A geometric transformations group, in which we applied multiple transformations that are of geomtric nature : rotations, rescaling, \"Zooming\" (cropping and resizing), shearing. \n",
        "3.  A non-geometric transformations group, in which we applied multiple transformations that are of non-geomtric nature : Noise (gaussian noise), blur and compression\n",
        "3.  A mixed transformations group, in which we applied both geometric and non-geometric transformations. We however did not use shearing and \"Zooming\" transformations as these empirically lead to worse results. \n",
        "\n",
        "\n",
        "With more time, we would have liked to explore these transformations more in-depth with a greater variety of groups. Also, it would be interresting to tune the hyperparameters of these transformations : probability, cropping size, noise level, shearing dimenstions..."
      ],
      "metadata": {
        "id": "YeFyeMuVNl_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Definition of the different transformations\n",
        "\n",
        "#Baseline\n",
        "train_transform1 = [\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.VerticalFlip(p=0.5),\n",
        "  ]\n",
        "my_transform1 = A.Compose(train_transform1)\n",
        "\n",
        "\n",
        "#Geometric transformations\n",
        "train_transform2 = [\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.VerticalFlip(p=0.5),\n",
        "        A.RandomSizedCrop(min_max_height=\t[200,200], height = 400, width = 400, p = 0.5),\n",
        "        A.ShiftScaleRotate(p=0.5),\n",
        "        A.Affine(shear=[-10, 10], scale=1.1, fit_output=False, p=.1),\n",
        "    ]\n",
        "my_transform2 = A.Compose(train_transform2)\n",
        "\n",
        "\n",
        "#Non-geometric transformations        \n",
        "train_transform3 = [\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.VerticalFlip(p=0.5),\n",
        "        A.GaussNoise(var_limit=(.001, .03), p=.5),\n",
        "        A.Blur(blur_limit=5., p=.2),\n",
        "        A.ImageCompression(quality_lower=50, p=.2),\n",
        "    ]\n",
        "my_transform3 = A.Compose(train_transform3)\n",
        "\n",
        "\n",
        "#mixed transformations\n",
        "train_transform4 = [\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.VerticalFlip(p=0.5),\n",
        "        A.ShiftScaleRotate(p=0.5),\n",
        "        A.GaussNoise(var_limit=(.001, .03), p=.5),\n",
        "        A.Blur(blur_limit=5., p=.2),\n",
        "        A.ImageCompression(quality_lower=50, p=.2),\n",
        "    ]\n",
        "my_transform4 = A.Compose(train_transform4)\n"
      ],
      "metadata": {
        "id": "wUpr640iNpvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating the train and validation dataloaders\n",
        "\n",
        "After research and testing on the subject, we arrived at the conclusion that implemeting a cross-validation to optimize our hyper parameters is not a viable option. Indeed, the requierd computation power is well above our possibilities.\n",
        "\n",
        "As such, we decided an alternative approach : define a small and random validation set to tune the parameters to some extent. We shall be carefull as the variance of this validation may be high and we shall be vary as not to overfit the validation set. "
      ],
      "metadata": {
        "id": "TXQQa3IdP4Yz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 4\n",
        "validation_split = .15\n",
        "shuffle_dataset = True\n",
        "random_seed= 1"
      ],
      "metadata": {
        "id": "s3IsN6Y9KI63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training the 4 models\n",
        "\n",
        "Note : we used only 30 epochs for these models as we could not afford to wait 10h+ for all models to train with 150-200 epochs.\n",
        "\n",
        "**These 4 cells below do not need to be run !** The models are saved in the drive and are reloaded in the cells further below"
      ],
      "metadata": {
        "id": "bB50FNwRLuRt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#NO NEED TO RUN THE CELL, MODEL IS SAVED AND RELOADED LATER\n",
        "\n",
        "#initializing the dataset and associated dataloaders for baseline transformations group\n",
        "dataset = CustomDataset(transform=my_transform1)\n",
        "\n",
        "# Creating data indices for training and validation splits:\n",
        "dataset_size = len(dataset)\n",
        "indices = list(range(dataset_size))\n",
        "split = int(np.floor(validation_split * dataset_size))\n",
        "if shuffle_dataset :\n",
        "    np.random.seed(random_seed)\n",
        "    np.random.shuffle(indices)\n",
        "train_indices, val_indices = indices[split:], indices[:split]\n",
        "\n",
        "# Creating PT data samplers and loaders:\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "valid_sampler = SubsetRandomSampler(val_indices)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
        "validation_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler)\n",
        "\n",
        "#train the model for transforms1\n",
        "l_unet = Lit_Net(in_chans=3, out_chans=1)\n",
        "trainer = pl.Trainer(max_epochs = 30, progress_bar_refresh_rate=1, gpus=1, auto_scale_batch_size=True, accumulate_grad_batches=1)\n",
        "trainer.fit(l_unet, train_dataloaders = train_loader)\n",
        "\n",
        "#Saving the model\n",
        "path = os.path.join('drive/MyDrive/Projet_ML/trained_models/unet_30epoch_transformations1.pth')\n",
        "torch.save(l_unet, path)"
      ],
      "metadata": {
        "id": "s-d0izJeNbml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#NO NEED TO RUN THE CELL, MODEL IS SAVED AND RELOADED LATER\n",
        "\n",
        "#initializing the dataset and associated dataloaders for geometric transformations group\n",
        "dataset = CustomDataset(transform=my_transform2)\n",
        "\n",
        "# Creating data indices for training and validation splits:\n",
        "dataset_size = len(dataset)\n",
        "indices = list(range(dataset_size))\n",
        "split = int(np.floor(validation_split * dataset_size))\n",
        "if shuffle_dataset :\n",
        "    np.random.seed(random_seed)\n",
        "    np.random.shuffle(indices)\n",
        "train_indices, val_indices = indices[split:], indices[:split]\n",
        "\n",
        "# Creating PT data samplers and loaders:\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "valid_sampler = SubsetRandomSampler(val_indices)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
        "validation_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler)\n",
        "\n",
        "#train the model for transforms1\n",
        "l_unet = Lit_Net(in_chans=3, out_chans=1)\n",
        "trainer = pl.Trainer(max_epochs = 30, progress_bar_refresh_rate=1, gpus=1, auto_scale_batch_size=True, accumulate_grad_batches=1)\n",
        "trainer.fit(l_unet, train_dataloaders = train_loader)\n",
        "\n",
        "#Saving the model\n",
        "path = os.path.join('drive/MyDrive/Projet_ML/trained_models/unet_30epoch_transformations2.pth')\n",
        "torch.save(l_unet, path)"
      ],
      "metadata": {
        "id": "OeGV2M-hMe7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#NO NEED TO RUN THE CELL, MODEL IS SAVED AND RELOADED LATER\n",
        "\n",
        "#initializing the dataset and associated dataloaders for non-geometric transformations group\n",
        "dataset = CustomDataset(transform=my_transform3)\n",
        "\n",
        "# Creating data indices for training and validation splits:\n",
        "dataset_size = len(dataset)\n",
        "indices = list(range(dataset_size))\n",
        "split = int(np.floor(validation_split * dataset_size))\n",
        "if shuffle_dataset :\n",
        "    np.random.seed(random_seed)\n",
        "    np.random.shuffle(indices)\n",
        "train_indices, val_indices = indices[split:], indices[:split]\n",
        "\n",
        "# Creating PT data samplers and loaders:\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "valid_sampler = SubsetRandomSampler(val_indices)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
        "validation_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler)\n",
        "\n",
        "#train the model for transforms1\n",
        "l_unet = Lit_Net(in_chans=3, out_chans=1)\n",
        "trainer = pl.Trainer(max_epochs = 30, progress_bar_refresh_rate=1, gpus=1, auto_scale_batch_size=True, accumulate_grad_batches=1)\n",
        "trainer.fit(l_unet, train_dataloaders = train_loader)\n",
        "\n",
        "#Saving the model\n",
        "path = os.path.join('drive/MyDrive/Projet_ML/trained_models/unet_30epoch_transformations3.pth')\n",
        "torch.save(l_unet, path)"
      ],
      "metadata": {
        "id": "eUI_MftqL2gF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#NO NEED TO RUN THE CELL, MODEL IS SAVED AND RELOADED LATER\n",
        "\n",
        "#initializing the dataset and associated dataloaders for mixed transformations group\n",
        "dataset = CustomDataset(transform=my_transform4)\n",
        "\n",
        "# Creating data indices for training and validation splits:\n",
        "dataset_size = len(dataset)\n",
        "indices = list(range(dataset_size))\n",
        "split = int(np.floor(validation_split * dataset_size))\n",
        "if shuffle_dataset :\n",
        "    np.random.seed(random_seed)\n",
        "    np.random.shuffle(indices)\n",
        "train_indices, val_indices = indices[split:], indices[:split]\n",
        "\n",
        "# Creating PT data samplers and loaders:\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "valid_sampler = SubsetRandomSampler(val_indices)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
        "validation_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler)\n",
        "\n",
        "#train the model for transforms1\n",
        "l_unet = Lit_Net(in_chans=3, out_chans=1)\n",
        "trainer = pl.Trainer(max_epochs = 30, progress_bar_refresh_rate=1, gpus=1, auto_scale_batch_size=True, accumulate_grad_batches=1)\n",
        "trainer.fit(l_unet, train_dataloaders = train_loader)\n",
        "\n",
        "\n",
        "path = os.path.join('drive/MyDrive/Projet_ML/trained_models/unet_30epoch_transformations4.pth')\n",
        "torch.save(l_unet, path)"
      ],
      "metadata": {
        "id": "_hU15J6UL2WX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evalutating the models\n",
        "\n",
        "### helper functions:"
      ],
      "metadata": {
        "id": "6uaccOSlQt0D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "#Threshold function, which always thresholds an image with the given threshold value\n",
        "def create_threshold(threshold):\n",
        "    return lambda pred : pred > threshold\n",
        "\n",
        "#Applies a threshold function to the predictions, and computes the f1 score with respect to the target images\n",
        "def compute_score_thresholded(threshold_func, preds, target):\n",
        "    thresholded = np.stack([threshold_func(sigmoid_v(pred)) for pred in preds])\n",
        "    return f1_score(np.ravel(target), np.ravel(thresholded.astype(int)))\n",
        "\n",
        "#Selects the best threshold with respect to f1-score from the given predictions and target images\n",
        "def select_best_threshold(threshold_funcs, preds, target):\n",
        "    assert len(preds) == len(target)\n",
        "    best_func = None\n",
        "    best_thresh = 0\n",
        "    best_score = 0\n",
        "    for threshold, threshold_func in threshold_funcs:\n",
        "        score = compute_score_thresholded(threshold_func, preds, target)\n",
        "        if score > best_score:\n",
        "            best_thresh = threshold\n",
        "            best_score = score\n",
        "            best_func = threshold_func\n",
        "    return best_func, best_thresh, best_score\n",
        "\n",
        "#used for iterating on dataloader\n",
        "def cycle(iterable):\n",
        "    while True:\n",
        "        for x in iterable:\n",
        "            yield x\n",
        "\n",
        "# custom sigmoid function\n",
        "def sigmoid(x):\n",
        "  return 1 / (1 + np.exp(-x))\n",
        "\n",
        "# define vectorized sigmoid\n",
        "sigmoid_v = np.vectorize(sigmoid)\n",
        "\n",
        "#initialize the thresholds\n",
        "THRESHOLDS = [(x,create_threshold(x)) for x in np.linspace(0.1,0.7,num=20)]"
      ],
      "metadata": {
        "id": "kC8M5Cz_O5b9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reloading datasets and dataloaders\n",
        "\n",
        "To evaluate the model, we must reload all dataloaders and datasets. While this is not optimal in terms of coding as all these where initialized in earlier cells, we must proceed this way to save RAM memory and save GPU power.\n",
        "\n",
        "Indeed, after training the models we saved them onto our drive and can now reload them. This way, this second part is effectively segmented from the training which enables us to run it separately.\n"
      ],
      "metadata": {
        "id": "OkoYrzqn70Qb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Evalutating model with baseline transformations\n",
        "dataset = CustomDataset(transform=my_transform1)\n",
        "\n",
        "#Creating data indices for training and validation splits:\n",
        "dataset_size = len(dataset)\n",
        "indices = list(range(dataset_size))\n",
        "split = int(np.floor(validation_split * dataset_size))\n",
        "if shuffle_dataset :\n",
        "    np.random.seed(random_seed)\n",
        "    np.random.shuffle(indices)\n",
        "train_indices, val_indices = indices[split:], indices[:split]\n",
        "\n",
        "# Creating PT data samplers and loaders:\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "valid_sampler = SubsetRandomSampler(val_indices)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
        "validation_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler)\n",
        "\n",
        "\n",
        "path = os.path.join('drive/MyDrive/Projet_ML/trained_models/unet_30epoch_transformations1.pth')\n",
        "model = torch.load(path)\n",
        "model.eval()\n",
        "val_iter = iter(cycle(validation_loader))\n",
        "\n",
        "preds = []\n",
        "targets = []\n",
        "for i in range(len(val_indices)):\n",
        "  print(\"iter\", i)\n",
        "  data = next(val_iter)\n",
        "  x,y = data\n",
        "  preds.append(model(x)[0].detach().numpy())\n",
        "  targets.append(y[0].detach().numpy())\n",
        "\n",
        "best_func1, best_thresh1, best_score1 = select_best_threshold(THRESHOLDS, np.array(preds), np.round(np.array(targets)))\n",
        "print(\"Best score for baseline transformations :\",best_score1) "
      ],
      "metadata": {
        "id": "d8hq_70HfR3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evalutating model with geometric transformations\n",
        "\n",
        "dataset = CustomDataset(transform=my_transform2)\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
        "validation_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler)\n",
        "\n",
        "\n",
        "path = os.path.join('drive/MyDrive/Projet_ML/trained_models/unet_30epoch_transformations2.pth')\n",
        "model = torch.load(path)\n",
        "model.eval()\n",
        "val_iter = iter(cycle(validation_loader))\n",
        "\n",
        "preds = []\n",
        "targets = []\n",
        "for i in range(len(val_indices)):\n",
        "  print(\"iter\", i)\n",
        "  data = next(val_iter)\n",
        "  x,y = data\n",
        "  preds.append(model(x)[0].detach().numpy())\n",
        "  targets.append(y[0].detach().numpy())\n",
        "\n",
        "best_func2, best_thresh2, best_score2 = select_best_threshold(THRESHOLDS, np.array(preds), np.round(np.array(targets)))\n",
        "print(\"Best score for geometric transformations :\",best_score2) "
      ],
      "metadata": {
        "id": "eDNNGxpFmp83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evalutating model with geometric transformations\n",
        "\n",
        "dataset = CustomDataset(transform=my_transform3)\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
        "validation_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler)\n",
        "\n",
        "\n",
        "path = os.path.join('drive/MyDrive/Projet_ML/trained_models/unet_30epoch_transformations3.pth')\n",
        "model = torch.load(path)\n",
        "model.eval()\n",
        "val_iter = iter(cycle(validation_loader))\n",
        "\n",
        "preds = []\n",
        "targets = []\n",
        "for i in range(len(val_indices)):\n",
        "  print(\"iter\", i)\n",
        "  data = next(val_iter)\n",
        "  x,y = data\n",
        "  preds.append(model(x)[0].detach().numpy())\n",
        "  targets.append(y[0].detach().numpy())\n",
        "\n",
        "best_func3, best_thresh3, best_score3 = select_best_threshold(THRESHOLDS, np.array(preds), np.round(np.array(targets)))\n",
        "print(\"Best score for non-geometric transformations :\",best_score3) "
      ],
      "metadata": {
        "id": "RDVBgtWJQsj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evalutating model with geometric transformations\n",
        "\n",
        "dataset = CustomDataset(transform=my_transform4)\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
        "validation_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler)\n",
        "\n",
        "\n",
        "path = os.path.join('drive/MyDrive/Projet_ML/trained_models/unet_30epoch_transformations4.pth')\n",
        "model = torch.load(path)\n",
        "model.eval()\n",
        "val_iter = iter(cycle(validation_loader))\n",
        "\n",
        "preds = []\n",
        "targets = []\n",
        "for i in range(len(val_indices)):\n",
        "  print(\"iter\", i)\n",
        "  data = next(val_iter)\n",
        "  x,y = data\n",
        "  preds.append(model(x)[0].detach().numpy())\n",
        "  targets.append(y[0].detach().numpy())\n",
        "\n",
        "best_func4, best_thresh4, best_score4 = select_best_threshold(THRESHOLDS, np.array(preds), np.round(np.array(targets)))\n",
        "print(\"Best score for mixed transformations :\",best_score4) "
      ],
      "metadata": {
        "id": "P-c_WAk8fsp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Best score for baseline transformations :\", best_score1,\"\\n\", \"Best score for geometric transformations :\", best_score2, \"\\n\", \n",
        "      \"Best score for non-geometric transformations :\", best_score3, \"\\n\", \"Best score for mixed transformations :\", best_score4)"
      ],
      "metadata": {
        "id": "DT4NjkDop8ON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "  As expected, geometric transformations yield the worse results, as these do not preserve the geometry of the roads. Cropping and shearing may results in a loss of information about the links between the pixels, which plays an important role in unets and in the task at hand.\n",
        "\n",
        "  It may seem surprising that the best evaluation here is the baseline model with very few transformations. This is likely due to the fact that this model is \"easier\" to train as there are less different pictures. It therefore gives the best results when trained with only 30 epochs. As mentionned earlier, due to time limits and Google colab GPU usage limits we could not train these models with a higher number of epochs.\n",
        "\n",
        "  Empirically, the models that worked best were mixed models, without cropping or shearing. This results can be observed here."
      ],
      "metadata": {
        "id": "qNy74D7up7on"
      }
    }
  ]
}