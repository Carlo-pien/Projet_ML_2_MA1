{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "README.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPmD/e2mSF1w40Z4B4EGsVi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Carlo-pien/Projet_ML_2_MA1/blob/master/README.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Road Segmentation 2021-CS-433 Machine Learning\n",
        "\n",
        "<img src=\"https://user-images.githubusercontent.com/32189761/135729218-8829924c-c89b-490f-87e7-0befc8adcdf6.png\" alt=\"Segmentation\" height=\"200px\"/> CHANGER L'IMAGE!!!!!\n",
        "\n",
        "This github contains the different files used to create our submissions on *AIcrowd*. [EPFL Aicrowd Road Segmentation challenge](https://www.aicrowd.com/challenges/epfl-ml-road-segmentation).\n",
        "\n",
        "In order to understand better what techniques we used, the best way is to read through the **Experiments.ipynb** notebook, which explains our usage of U-Nets, our selection of Data Augmentation, the Sliding Window technique we used to provide robustness, and different types of post processing methods attempted.\n",
        "\n",
        "\n",
        "## Libraries used and Execution Guide\n",
        "\n",
        "\n",
        "<details>\n",
        "  <summary>Click to show / hide</summary>\n",
        "<br>\n",
        "  \n",
        "All the notebooks included were run using google colab, we thus recommend google colab for their execution. Should a local alternative be desirable, however the following versions of libraries, along with a version of python of 3.6.9 (the one present on google colab) are required:\n",
        "\n",
        "```\n",
        "imgaug==0.2.9\n",
        "tensorflow==2.3.0\n",
        "tensorflow-addons==0.8.3\n",
        "tensorflow-datasets==4.0.1\n",
        "tensorflow-estimator==2.3.0\n",
        "tensorflow-gcs-config==2.3.0\n",
        "tensorflow-hub==0.10.0\n",
        "tensorflow-metadata==0.25.0\n",
        "tensorflow-privacy==0.2.2\n",
        "tensorflow-probability==0.11.0\n",
        "Keras==2.4.3\n",
        "matplotlib==3.2.2\n",
        "seaborn==0.11.0\n",
        "numpy==1.18.5\n",
        "sklearn==0.22.2.post1\n",
        "tqdm==4.41.1\n",
        "```\n",
        "\n",
        "Further, we cannot guarantee that any GPU can execute the same training as on colab, which contains a 16 GB GPU. Locally training a level 7 U-Net was an impossibility for us, as we ended up having OutOfMemory errors on local GPUs.\n",
        "\n",
        "In order to run the run.py script, you will also need the wget library.\n",
        "\n",
        "</details>\n",
        "\n",
        "## Use of Google Colab\n",
        "\n",
        "<details>\n",
        "  <summary>Click to show / hide</summary>\n",
        "<br>\n",
        "\n",
        "To run our experiences made for this project with GPUs, we decided to use *Google Colab*. For that reason, our files are on this platform and use also *Google drive*. Thus, to run them, you need to follow the steps below:\n",
        "\n",
        "- Access this link that points to our Code Folder, named \"Project_ML\" : https://drive.google.com/drive/folders/1BdVy8AukS7MS5bqCxJuJMF2N-cUwKluq?usp=sharing\n",
        "- Add a shortcut to the Code Folder inside your root drive (Right-click on the folder, add a shortcut inside Drive), without changing the name\n",
        "- When running a notebook, make sure that the Drive mount folder shows our code folder inside /content/drive/MyDrive, otherwise, the shortcut either has the wrong name, or is at the wrong location\n",
        "- Sometimes colab allocates you worse GPUs than necessary, so you may need to reconnect to another machine if you try to train a model and get an OutOfMemory error when allocating Tensors.\n",
        "\n",
        "Here is a description of everything in our Code Folder :\n",
        "- archive : We kept most previous versions of our notebooks for completeness in this folder\n",
        "- libs : All python libraries are kept under this folder (even those provided)\n",
        "- models : All pretrained weights and models are in this folder\n",
        "- submissions : We kept csv files for all important submissions in this folder.\n",
        "- test_predictions : We kept image predictions for all important submissions in this folder\n",
        "- test_set_images : The folder of test images\n",
        "- training : The folder of training images\n",
        "- validation_predictions : The image predictions that are done on our validation sets in our Experiments notebook are kept here.\n",
        "- vis_postprocessing : Figures appearing in the report relating to postprocessing.\n",
        "- ipynb files : All notebooks are described later\n",
        "- run.py file: Same as the run.py in the github classroom folder, here for ease of use of the Running.ipynb notebook\n",
        "\n",
        "</details>\n",
        "\n",
        "## Our different documents\n",
        "\n",
        "<details>\n",
        "  <summary>Click to show / hide</summary>\n",
        "<br>\n",
        "  \n",
        "### The run.py file\n",
        "\n",
        "The run.py performs the following steps :\n",
        "\n",
        "- Downloading our best model\n",
        "- Predicting the test images\n",
        "- Creating a submission file\n",
        "\n",
        "It uses tensorflow (and preferrably tensorflow-gpu, otherwise it is very slow) in order to run, and may not work with GPUs that have a lower amount of memory than the ones on colab.\n",
        "It is also possible to train a model using the same parameters as our best model, instead of downloading the best model, but we again don't recommend it because it took us many hours to train it, on Colab GPUs. Keep in mind that even predicting may take some time due to our usage of sliding windows for prediction.\n",
        "\n",
        "There are some parameters you can set in the run.py, they are :\n",
        "- STRIDE : This parameter changes the stride parameter used in the sliding window, computation, it can be set to higher values (listed in the run.py file) for lesser computation time\n",
        "- TRAIN : When set to true, trains a model from \"scratch\" (still need weight initalization), instead of downloading our best model\n",
        "- BEST_RESULT : When set to true, doesn't use the best parameters we found based on our validation f1-score, but instead uses parameters we found when performing a random search on post-processing.\n",
        "\n",
        "In order to run it using Colab, we provided you with a notebook called Running.ipynb in the aforementioned code folder. It simply installs the wget library and runs the run.py folder, to create the submission.\n",
        "\n",
        "### The NN Notebook\n",
        "\n",
        "The `nn.ipynb` notebook combines most of our experiments attempted on this project. \n",
        "\n",
        "Most cells have to be run on Google Colab or at least using similar/better GPUs (Nvidia K80 at least, but we can't guarantee that they didn't change since), although we don't even necessarily recommend running them, because training models can take multiple hours. Everything is already run, with shown output so that you can look at code and corresponding output.\n",
        "\n",
        "It is divided into parts which are :\n",
        "\n",
        "- Selecting Data Augmentation\n",
        "- Selecting the level of our U-Net\n",
        "- Best Input Size (and sliding window size)\n",
        "- Best stride for our sliding window\n",
        "- Trying out weighted loss\n",
        "- Averaging models\n",
        "- Post-Processing methods to use\n",
        "\n",
        "### The \"Model\" Notebooks\n",
        "\n",
        "These notebooks correspond to the models which we've considered to be noteworthy. They showcase how we train each model.\n",
        "\n",
        "#### The Level 7 notebook\n",
        "\n",
        "The level 7 notebook is most straightforward one, it simply showcases a normal level 7 model.\n",
        "\n",
        "#### The AveragingModels notebook\n",
        "\n",
        "This notebook showcases the training / loading of multiple level 5 models in order to average out the predictions, as an ensemble method.\n",
        "\n",
        "#### The Weighted Level 7 notebook\n",
        "\n",
        "This notebook showcases the training of a level 7 model which uses a weighted loss instead of binary cross entropy. That is, instead of giving equal weights to roads and background in the computation of the loss, we tried giving more or less weights, in order to tacke the class imbalance problem.\n",
        "\n",
        "### The file libraries\n",
        "\n",
        "In order to tidy up code inside the notebooks, we chose to move all shared / boilerplate code inside different python files which we use as libraries (listed under the libs folder).\n",
        "\n",
        "#### image_gen.py\n",
        "\n",
        "- random_crop\n",
        "Given two images and a crop size, returns a tuple of cropped patches of given size, selected at the saame position in both images\n",
        "- crop_generator\n",
        "Given a generator of x,y samples, creates a generator that crops all images to the size given\n",
        "- force_batch_size\n",
        "Given a generator of x,y samples, creates a generator that returns only images that have the right batch size\n",
        "- mask_to_block\n",
        "Returns a view on the given mask as blocks, by averaging values in the mask\n",
        "- block_generator\n",
        "Given a generator of x,y samples, creates a generator that returns images as blocks, by using mask_to_block and a given threshold\n",
        "- ImageGenerator\n",
        "Given augmentation parameters, directories for input, and target images, and extra parameters, setups multiple generators, to be returned using the following methods :\n",
        "  - get_normal_generator\n",
        "    - Returns train and validation generators by appling augments\n",
        "  - get_crop_generator\n",
        "    - Returns a crop generator, applying crop_generator function on the get_normal_generator \n",
        "  - get_block_generator\n",
        "    - Returns a crop generator, applying crop_generator function on the get_normal_generator or get_crop_generator (if given a crop_length)\n",
        "\n",
        "#### models.py\n",
        "\n",
        "- last_layers\n",
        "Post processing CNN that fills segments\n",
        "- unet\n",
        "Returns a U-Net model from given parameters, with ability to specify input size, levels, pretrained weights, optimizer, callbacks, and using a post-processing CNN, using the last_layers function\n",
        "\n",
        "#### sliding_windows.py\n",
        "\n",
        "- windows_from_image\n",
        "Returns window views on the given image, of size and stride given\n",
        "- plot_windows\n",
        "Used for debug, plots the provided windows\n",
        "- image_from_windows\n",
        "Recovers the image from the windows given (inverse of windows_from_image)\n",
        "- pred_to_uint8\n",
        "Converts float prediction to uint8\n",
        "- predict_from_image\n",
        "Gets window views on image, predicts roads pixel-wise all those windows, aggregates result of predictions back together to predict a complete image\n",
        "- pad_border\n",
        "Pads an image with zeros\n",
        "- rotate_image\n",
        "Applies affine rotation to images\n",
        "- predict_from_image_rotated\n",
        "Gets window views on image, predicts roads pixel-wise all those windows with applying given rotations, with or without padding depending on argument,and then aggregates result of predictions back together to predict a complete image\n",
        "\n",
        "#### post_process.py\n",
        "\n",
        "- morphological\n",
        "Applies the given cv2 morphological operations to the image, using column, row, and square kernels sequentially\n",
        "- open_pred\n",
        "Applies the cv2.MORPH_OPEN operation to the image, using morphological\n",
        "- close_pred\n",
        "Applies the cv2.MORPH_CLOSE operation to the image, using morphological\n",
        "- smooth_predictions\n",
        "Applies Gaussian smoothing, for multiple steps in a row, with the given kernel size\n",
        "- hough_find_lines\n",
        "Returns all found lines using the Hough transform for lines and given parameters\n",
        "- keep_large_area\n",
        "Keeps only blobs of large enough area, with threshold as argument\n",
        "\n",
        "#### submission.py\n",
        "\n",
        "This file combines some of the provided functions, and adds other related to creating a submission.\n",
        "\n",
        "- load_test_images\n",
        "Loads all test images from the given directory\n",
        "- save_predictions_to_folder\n",
        "Saves all predictions (list of images) to given folder\n",
        "- patch_to_label\n",
        "Provided function : assign a label to a patch\n",
        "- mask_to_submission_strings\n",
        "Provided function : Reads a single image and outputs the strings that should go into the submission file\n",
        "- masks_to_submission\n",
        "Provided function : Converts images into a submission file\n",
        "- create_submission\n",
        "Creates a submission given ordered predictions\n",
        "- binary_to_uint8\n",
        "Converts binary labels to uint8\n",
        "- reconstruct_from_labels\n",
        "Provided function : Reconstruct images from label files\n",
        "- plot_submission\n",
        "Plots reconstructed submissions when provided a submission file, using reconstruct_from_labels\n",
        "\n",
        "#### threshold.py\n",
        "\n",
        "- middle_threshold\n",
        "Thresholds an image using the value between the min and max pixel values of the image\n",
        "- create_vanilla_threshold\n",
        "Creates a threshold function, which always thresholds an image with the given threshold value\n",
        "- create_percentile_threshold\n",
        "Creates a threshold function, which always thresholds an image with the percentile value (if a pixel is a higher value than the median for percentile = 0.5 for example)\n",
        "- compute_score_thresholded\n",
        "Applies a threshold function to the predictions, and computes the f1 score with respect to the target images\n",
        "- select_best_threshold\n",
        "Selects the best threshold with respect to f1-score from the given (threshold, threshold_func) pairs, predictions and target images\n",
        "\n",
        "\n",
        "#### averaging.py\n",
        "\n",
        "- generate_F1_weights\n",
        "Generates the custom weights for the average by giving more importance to the models with a higher F1 score\n",
        "The importance of the F1_score can be customized by giving a minimum weight to all models with cst_weight_prc\n",
        "- average_prediction\n",
        "Takes a array of array of predictions and computes the mean item by item. The average can either be fair if no weights are set.\n",
        "It can also be customized by passing it custom weights.\n",
        "\n",
        "\n",
        "#### augmentation.py\n",
        "\n",
        "- apply_augmentation\n",
        "Augments the provided images by applying rotations of 0,90,180,270 degrees and flips\n",
        "\n",
        "</details>\n",
        "\n",
        "----\n",
        "\n",
        "### Authors :\n",
        "\n",
        "- Ghenassia Noam\n",
        "- Nussbaumer Arthur\n",
        "- Piening Carlo"
      ],
      "metadata": {
        "id": "b4cK3pl0LHSN"
      }
    }
  ]
}